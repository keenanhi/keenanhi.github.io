---
title: Get Started Part 1
layout: post
description: This is the first part of the Get Started mini series. This part of the series answers the question what is mastering? It also briefly runs through the entire process of recording and mixing audio
---

##What is Digital Audio?


Welcome to the Get Started mini-series!

In this series, we will review the foundations of the modern music production process. If you’re totally new to this stuff, this is the place for you, and even if you have experience, reviewing the basics never hurts!

The series will be split into three sections:

**Part 1: What is Digital Audio?** An overview of sound, and how it travels from the physical to the electrical realm (hint: you are reading this one)

**Part 2: What is Mastering?** A full overview of the modern recording process, including tools used in altering recorded music.

**Part 3: How do I Master My Own Music?** An overview of mix preparation and your toolkit as a mastering engineer

This series will also frequently reference the glossary I am actively cultivating. Don’t just skip over words that confuse you; learning this vocab now will save you headaches later, plus you can impress all your friends when you can point out sidechain compression on the kick in that EDM song at that party (if they can hear you over the bass, that is)

So let’s Get Started by answering the question:

###What is sound?

Sound is our perception of a material's variation of pressure versus time through our ears, and the auditory processing parts of our brain. Typically, this material will be air, though - and I hope I don’t sound crazy - we can perceive variation of pressure in other materials too, like water! Just fill up your tub, stick your head underwater, and listen for your roommates to ask you what on earth you are doing. For now, however, we are just going to deal with air, since most of us aren’t listening to music underwater ([most of us](https://www.youtube.com/watch?v=TeChHVAbVhI)).

Air can vibrate quickly, and air can vibrate slowly. The rate at which air molecules vibrate is called a sound's **frequency**. When air vibrates quickly, it has a high frequency, and when it vibrates slowly, it has a low frequency. 

The unit of frequency is **Hertz** (abbreviated Hz), which simply means cycles per second. If a sound is oscillating at 100 Hz, that means that air molecules are moving back and forth 100 times every second.

Now, these moving air molecules have a funny effect on our ears: if air vibrates at a frequency anywhere between 20 Hz and 20,000 Hz, we can hear it as sound. Other animals can hear different ranges of frequencies that we cannot ([dogs, for instance, can hear frequencies above 20,000 Hz](https://www.youtube.com/watch?v=dk0HsvQ7m_E))

### Fundamental Frequency, Harmonics, and Pitch

In nearly all real life scenarios, sound will not consist of one frequency, but of many, many different frequencies layered upon each other. The lowest of these frequencies is called the **fundamental frequency** of a sound. Every other frequency within the sound is called a **harmonic**.

Our brains translate these fundamental frequencies into something we call **pitch**. When you hit a middle C on a piano, you hear a pitch corresponding to that key's fundamental frequency, which is, in this case, 261.6 Hz. This is the lowest frequency in the sound you hear when you hear a middle C on a piano, *but* there are still harmonics above this, which are translated by your brain as **timbre**, or the characteristic of the sound. If you listened to a trumpet playing concert middle C, you are still hearing the fundamentally frequency of 261.6 Hz as its pitch, but the trumpet's harmonics, and thus its timbre, are significantly different from that of a piano.

So remember: pitch is your brain's translation of fundamental frequency, and timbre is your brain's translation of harmonics [^notreally]

### Tone

Things start to get tricky, from a vocabulary perspective, when we try to separate timbre and **tone**. The definitions I am giving are by no means universally agreed upon, but will suffice for the sake of music production.

Whereas timbre is the typical collection of harmonics allowing you to distinguish different instruments, tone is a description of the *flavor* of that timbrel source. Think of different timbres as a specific kinds of food (e.g. french fries vs. pumpkin pie) and tone as certain flavorings of one type of food (salted french fries vs. unsalted french fries).

An electric guitar might be bright (lots of high frequency harmonics), distorted (lots of added unnatural harmonics), or warm (lots of pleasant sounding harmonics), for example. These are some examples of descriptors of tone; there are countless more that are often based more in musical slang than in science (e.g. muddy, clean, thick, crunchy, sparkly)


### Filters

Something cool us humans have figured out is that you can **filter** sounds. A filter is something that changes the strength of certain frequencies in a sound. Just as you might filter your coffee, you are, with a filter, removing parts of a sound, effectively "straining out" certain frequencies. If you think a grand piano has too much high-frequency harmonics, you can filter them out by closing the lid. When you close your bedroom door so that you don't have to hear Aunt Delilah talk about her new optomitrist, you are filtering out her voice, bringing down both the strength of the harmonics and fundamental frequencies of her voice.

What's more, air itself can act as a filter, if you get enough of it! If you have been to an outdoor concert, or seen a marching band, you'll notice that the further away you move from the sound source, the more air filters out high frequencies, while you can still hear lower frequency sounds like the bass guitar or bass drum.

In all of these cases, a physical object acts as a filter. Though all of these examples acted upon high frequency harmonics, filters can act on any range of frequencies. We tricky humans have figured out how to manipulate audio so that we can eliminate or accentuate certain frequencies in a much more exact way than by filtering sound through physical objects. When done electrically, filtering is called **equalization**, which we will come back to in Part 2 of Get Started.

### Loudness

When we filter a sound, we are changing the loudness of certain frequencies within that sound. So it makes sense to go back and ask the seemingly innocuous question: what is loudness?

**Loudness** is our brains translation of the strength of a sound, or, in other words, how hard the air molecules which make up a sound are vibrating[^notreally2]. Intuitively, the harder the air is a-shakin', the louder the sound is a-soundin', and conversly, the weaker the quieter. A sound's total loudness relates to the loudness of all of it's components: not just the fundamental frequency, and not just the harmonics.

With aaaaaaall that jargon out of the way, let's move from live sound on to the world of recorded sound in which we will be working.

### Recreating Sound

Of course,  you wouldn't be reading this now if recorded music didn't exist! So how to we make it sound like there is a rock band living inside of our computer speakers, ready to play any song at our will?

The trick lies in converting those wiggling air molecules into wiggling electrons. Just like music in the air consists of different frequencies of air molecule vibrations, music in your computer consists of different frequencies of electron vibrations.

How does your computer do this? To answer that, we need to understand the very basics of how a computer works.

### Digital Storage

Everything on your computer is based off of the concept of 


---



[^notreally]: note I keep saying *brain's translation* here; your brain is not always exact. This is outside the scope of this series, but I will come back to it some day. Just like most things concerning psychoacoustics, it's pretty trippy, and just a little too confusing for now.

[^notreally2]: see above

	
